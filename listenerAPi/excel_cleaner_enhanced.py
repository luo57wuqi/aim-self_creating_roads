#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å½±åˆ€æ•°æ®è¡¨æ ¼æ¸…æ´—å·¥å…· - å¢å¼ºç‰ˆ
æ”¯æŒæ™ºèƒ½åˆ—ååŒ¹é…å’Œæ¨¡ç³Šæœç´¢
"""

import csv
import json
import os
import sys
from typing import List, Dict, Any

class EnhancedDataCleaner:
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.headers = []
        self.data = []
    
    def read_file(self) -> bool:
        """è¯»å–æ–‡ä»¶"""
        # ä¼˜å…ˆå°è¯•CSVæ–‡ä»¶
        csv_file = os.path.splitext(self.file_path)[0] + '.csv'
        if os.path.exists(csv_file):
            return self.read_csv(csv_file)
        
        # å°è¯•Excelæ–‡ä»¶
        try:
            import xlrd
            workbook = xlrd.open_workbook(self.file_path)
            sheet = workbook.sheet_by_index(0)
            
            self.headers = [str(sheet.cell_value(0, col)) for col in range(sheet.ncols)]
            
            for row in range(1, sheet.nrows):
                row_data = {}
                for col in range(sheet.ncols):
                    value = sheet.cell_value(row, col)
                    if value is None:
                        value = ''
                    else:
                        value = str(value).strip()
                    row_data[self.headers[col]] = value
                self.data.append(row_data)
            
            print(f"æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼Œå…±{len(self.data)}è¡Œæ•°æ®")
            return True
            
        except ImportError:
            print("xlrdåº“æœªå®‰è£…ï¼Œå°è¯•CSVæ–¹å¼...")
        except Exception as e:
            print(f"è¯»å–Excelå¤±è´¥: {e}")
        
        return False
    
    def read_csv(self, csv_path: str) -> bool:
        """è¯»å–CSVæ–‡ä»¶"""
        encodings = ['utf-8-sig', 'utf-8', 'gbk', 'gb2312', 'gb18030']
        
        for encoding in encodings:
            try:
                with open(csv_path, 'r', encoding=encoding) as file:
                    reader = csv.DictReader(file)
                    self.headers = reader.fieldnames
                    self.data = [row for row in reader]
                print(f"æˆåŠŸè¯»å–CSVæ–‡ä»¶({encoding}ç¼–ç )ï¼Œå…±{len(self.data)}è¡Œæ•°æ®")
                return True
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
                break
        
        return False
    
    def find_columns_intelligent(self, target_names: List[str]) -> Dict[str, str]:
        """æ™ºèƒ½æŸ¥æ‰¾ç›®æ ‡åˆ—å"""
        column_mapping = {}
        
        # å®šä¹‰åˆ«åæ˜ å°„
        alias_mapping = {
            "è´§å·": ["è´§å·", "å•†å“è´§å·", "ç¼–å·", "äº§å“ç¼–å·", "å•†å“ç¼–å·"],
            "å·²ä¹°": ["å·²ä¹°", "å·²è´­ä¹°", "è´­ä¹°æ•°é‡", "å·²è´­ä¹°æ•°é‡", "è´­ä¹°", "é”€é‡"],
            "ç²¾é€‰": ["ç²¾é€‰", "ç²¾é€‰æ ‡è®°", "æ˜¯å¦ç²¾é€‰", "æ¨è", "ç²¾é€‰å•†å“"],
            "æƒ³è¦": ["æƒ³è¦", "æƒ³è¦æ•°é‡", "æ”¶è—", "å…³æ³¨", "éœ€æ±‚"]
        }
        
        for target in target_names:
            found = False
            
            # æ£€æŸ¥åˆ«å
            if target in alias_mapping:
                for alias in alias_mapping[target]:
                    for header in self.headers:
                        header_clean = str(header).strip()
                        if alias == header_clean:
                            column_mapping[target] = header
                            print(f"âœ“ æ‰¾åˆ°åŒ¹é…: {target} -> {header}")
                            found = True
                            break
                    if found:
                        break
            
            if found:
                continue
            
            # æ¨¡ç³ŠåŒ¹é…
            target_lower = str(target).lower()
            best_match = None
            best_score = 0
            
            for header in self.headers:
                header_lower = str(header).lower().strip()
                
                # åŒ…å«å…³ç³»
                if target_lower in header_lower or header_lower in target_lower:
                    score = 85
                elif any(alias.lower() in header_lower for alias in alias_mapping.get(target, [])):
                    score = 80
                else:
                    score = 0
                
                if score > best_score:
                    best_match = header
                    best_score = score
            
            if best_match and best_score >= 60:
                column_mapping[target] = best_match
                print(f"âœ“ æ¨¡ç³ŠåŒ¹é…: {target} -> {best_match}")
            else:
                print(f"âœ— æœªæ‰¾åˆ°: {target}")
        
        return column_mapping
    
    def extract_and_clean(self, column_mapping: Dict[str, str]) -> List[Dict[str, str]]:
        """æå–å¹¶æ¸…æ´—æ•°æ®"""
        if not column_mapping:
            return []
        
        extracted = []
        for row in self.data:
            new_row = {}
            for target, source in column_mapping.items():
                value = row.get(source, '')
                
                # æ•°æ®æ¸…æ´—
                if value is None:
                    value = ''
                else:
                    value = str(value).strip()
                
                # ç‰¹æ®Šå¤„ç†
                if target == "å·²ä¹°" or target == "æƒ³è¦":
                    try:
                        value = str(int(float(value)))
                    except (ValueError, TypeError):
                        value = '0'
                
                elif target == "ç²¾é€‰":
                    value_lower = value.lower()
                    if value_lower in ['æ˜¯', '1', 'true', 'yes', 'y', 'âˆš']:
                        value = 'æ˜¯'
                    elif value_lower in ['å¦', '0', 'false', 'no', 'n', 'Ã—']:
                        value = 'å¦'
                    else:
                        value = 'å¦'
                
                new_row[target] = value
            extracted.append(new_row)
        
        return extracted
    
    def save_all_formats(self, data: List[Dict[str, str]], base_name: str) -> None:
        """ä¿å­˜æ‰€æœ‰æ ¼å¼"""
        if not data:
            print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        # CSVæ ¼å¼
        csv_file = f"{base_name}_å®Œæ•´æ¸…æ´—.csv"
        try:
            with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=data[0].keys())
                writer.writeheader()
                for row in data:
                    clean_row = {col: row.get(col, '') for col in data[0].keys()}
                    writer.writerow(clean_row)
            print(f"âœ“ å®Œæ•´CSV: {csv_file}")
        except Exception as e:
            print(f"ä¿å­˜CSVå¤±è´¥: {e}")
        
        # JSONæ ¼å¼
        json_file = f"{base_name}_æ¸…æ´—å.json"
        try:
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ“ JSON: {json_file}")
        except Exception as e:
            print(f"ä¿å­˜JSONå¤±è´¥: {e}")
        
        # TXTæ ¼å¼
        txt_file = f"{base_name}_æ¸…æ´—å.txt"
        try:
            with open(txt_file, 'w', encoding='utf-8') as f:
                headers = list(data[0].keys())
                f.write('\t'.join(headers) + '\n')
                for row in data:
                    values = [row.get(h, '') for h in headers]
                    f.write('\t'.join(values) + '\n')
            print(f"âœ“ TXT: {txt_file}")
        except Exception as e:
            print(f"ä¿å­˜TXTå¤±è´¥: {e}")
    
    def generate_detailed_report(self, data: List[Dict[str, str]], mapping: Dict[str, str]) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        if not data:
            return "æ— æ•°æ®"
        
        lines = []
        lines.append("=" * 60)
        lines.append("å½±åˆ€æ•°æ®è¡¨æ ¼æ¸…æ´—è¯¦ç»†æŠ¥å‘Š")
        lines.append("=" * 60)
        lines.append(f"åŸå§‹æ–‡ä»¶: {self.file_path}")
        lines.append("")
        
        lines.append("ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        lines.append(f"  æ€»è®°å½•æ•°: {len(data)} æ¡")
        lines.append(f"  åŸå§‹åˆ—æ•°: {len(self.headers)} ä¸ª")
        lines.append(f"  æå–åˆ—æ•°: {len(mapping)} ä¸ª")
        lines.append("")
        
        lines.append("ğŸ¯ åˆ—æ˜ å°„è¯¦æƒ…:")
        for target, source in mapping.items():
            lines.append(f"  {target} â† {source}")
        lines.append("")
        
        lines.append("ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        for col in data[0].keys():
            values = [row.get(col, '') for row in data]
            non_empty = sum(1 for v in values if str(v).strip())
            
            if col in ["å·²ä¹°", "æƒ³è¦"]:
                try:
                    numbers = [int(v) for v in values if str(v).strip().isdigit()]
                    total = sum(numbers)
                    avg = total / len(numbers) if numbers else 0
                    lines.append(f"  {col}: {non_empty}æ¡æœ‰å€¼, æ€»è®¡: {total}, å¹³å‡: {avg:.1f}")
                except:
                    lines.append(f"  {col}: {non_empty}/{len(data)} æ¡è®°å½•æœ‰å€¼")
            elif col == "ç²¾é€‰":
                yes_count = sum(1 for v in values if str(v) == 'æ˜¯')
                lines.append(f"  {col}: æ˜¯ {yes_count}æ¡, å¦ {len(data)-yes_count}æ¡")
            else:
                lines.append(f"  {col}: {non_empty}/{len(data)} æ¡è®°å½•æœ‰å€¼")
        
        return "\n".join(lines)

def main():
    """ä¸»å‡½æ•°"""
    excel_file = "å½±åˆ€æ•°æ®è¡¨æ ¼_20250916-143820.xlsx"
    
    if not os.path.exists(excel_file):
        print(f"é”™è¯¯: æ–‡ä»¶ {excel_file} ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿æ–‡ä»¶åœ¨å½“å‰ç›®å½•")
        return
    
    print("=" * 60)
    print("å½±åˆ€æ•°æ®è¡¨æ ¼æ™ºèƒ½æ¸…æ´—å·¥å…·")
    print("=" * 60)
    print(f"å¤„ç†æ–‡ä»¶: {excel_file}")
    
    cleaner = EnhancedDataCleaner(excel_file)
    
    # è¯»å–æ–‡ä»¶
    if not cleaner.read_file():
        print("\nè¯·å…ˆå°†Excelæ–‡ä»¶è½¬æ¢ä¸ºCSVæ ¼å¼:")
        print("1. ç”¨Excelæ‰“å¼€æ–‡ä»¶")
        print("2. æ–‡ä»¶ â†’ å¦å­˜ä¸º")
        print("3. é€‰æ‹© CSV UTF-8(é€—å·åˆ†éš”)")
        print("4. ä¿å­˜ä¸º: å½±åˆ€æ•°æ®è¡¨æ ¼_20250916-143820.csv")
        return
    
    print(f"\nåŸå§‹è¡¨å¤´: {cleaner.headers}")
    
    # æ™ºèƒ½æŸ¥æ‰¾ç›®æ ‡åˆ—
    targets = ["è´§å·", "å·²ä¹°", "ç²¾é€‰", "æƒ³è¦"]
    mapping = cleaner.find_columns_intelligent(targets)
    
    if not mapping:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•ç›®æ ‡åˆ—")
        print("å¯ç”¨åˆ—å:")
        for i, header in enumerate(cleaner.headers, 1):
            print(f"  {i}. {header}")
        return
    
    # æå–å¹¶æ¸…æ´—æ•°æ®
    extracted = cleaner.extract_and_clean(mapping)
    
    if not extracted:
        print("æ•°æ®æå–å¤±è´¥")
        return
    
    # ä¿å­˜æ‰€æœ‰æ ¼å¼
    base_name = os.path.splitext(excel_file)[0]
    cleaner.save_all_formats(extracted, base_name)
    
    # ç”Ÿæˆå¹¶ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report = cleaner.generate_detailed_report(extracted, mapping)
    report_file = f"{base_name}_è¯¦ç»†æŠ¥å‘Š.txt"
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ“ è¯¦ç»†æŠ¥å‘Š: {report_file}")
    except Exception as e:
        print(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    
    print("\n" + report)
    print("\n" + "=" * 60)
    print("âœ… æ¸…æ´—å®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶")
    print("=" * 60)

if __name__ == "__main__":
    main()